{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from elasticsearch import Elasticsearch\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = dd.read_table('msmarco-docs.tsv\\msmarco-docs.tsv', blocksize=100e6,header=None)\n",
    "doc_df.columns=['docid','url','title','body']\n",
    "qry_df = pd.read_table('msmarco-doctrain-queries.tsv\\queries.doctrain.tsv')\n",
    "qry_df.columns = ['qid', 'query']\n",
    "rel_df = pd.read_table('msmarco-doctrain-top100\\msmarco-doctrain-top100', delimiter=' ')\n",
    "rel_df.columns = ['qid', 'Q0','docid', 'rank', 'score', 'runstring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-bf7555d044e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtemp_doc_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrel_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'qid'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtemp_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtemp_doc_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'docid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mohammad Dareer\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36miterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mohammad Dareer\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    362\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mohammad Dareer\\anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mis_object_or_str_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_object_or_str_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0minferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minferred\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"interval\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"period\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib._try_infer_map\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mohammad Dareer\\anaconda3\\lib\\site-packages\\numpy\\core\\_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# provides dtype.name.__get__, documented as returning a \"bit name\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misbuiltin\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;31m# user dtypes don't promise to do anything special\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_id = 0\n",
    "temp_doc_id = []\n",
    "rel = {}\n",
    "for i, rec in rel_df.iterrows():\n",
    "    if(rec['qid'] == temp_id):\n",
    "        temp_doc_id.append(rec['docid'])\n",
    "    else:\n",
    "        rel[temp_id] = temp_doc_id\n",
    "        temp_id = rec['qid']\n",
    "        temp_doc_id = []\n",
    "        temp_doc_id.append(rec['docid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = doc_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers\n",
    "client = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "     basic_auth=(\"elastic\", \"elastic\")\n",
    ")\n",
    "resp = client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rec in doc_df.iterrows():\n",
    "    doc = {'id': rec['docid'], 'doc': rec['body']}\n",
    "    client.index(index=\"trec\",id = i , document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "            \"match\": {\n",
    "                \"doc\": 'what'\n",
    "            }\n",
    "        }\n",
    "           \n",
    "resp = client.search(index=\"trec\", query=query, size=100)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 473 Hits:\n"
     ]
    }
   ],
   "source": [
    "all = client.search(index=\"trec2\", query={\"match_all\": {}})\n",
    "print(\"Got %d Hits:\" % all['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "class QueryProcessor:\n",
    "\n",
    "    def __init__(self, nlp, keep=None):\n",
    "        self.nlp = nlp\n",
    "        self.keep = keep or {'PROPN', 'NUM', 'VERB', 'NOUN', 'ADJ'}\n",
    "\n",
    "    def generate_query(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        query = ' '.join(token.text for token in doc if token.pos_ in self.keep)\n",
    "        return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(true:list, predect:list):\n",
    "    f = 0\n",
    "    for t in true :\n",
    "        for p in predect:\n",
    "            if p == t:\n",
    "                f = f + 1\n",
    "    return (f / len(predect))\n",
    "def recall(true:list, predect:list):\n",
    "    f = 0\n",
    "    for t in true :\n",
    "        for p in predect:\n",
    "            if p == t:\n",
    "                f = f + 1\n",
    "    return f / len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class noprocess:\n",
    "    def __init__(self, keep=None):\n",
    "        self.truth =[]\n",
    "        self.predect =[]\n",
    "        self.keep = keep or {'PROPN', 'NUM', 'VERB', 'NOUN', 'ADJ'}\n",
    "\n",
    "\n",
    "\n",
    "    def removeWh(self ,q):\n",
    "        query = ''\n",
    "        tokens =  word_tokenize(q)\n",
    "        for word, tag in nltk.pos_tag(tokens):\n",
    "            print(word,tag)\n",
    "            if tag in  self.keep:\n",
    "                query = ' '.join(word)\n",
    "        return query\n",
    "\n",
    "\n",
    "    def getTruth(self, id):\n",
    "        doc_list = []\n",
    "        for i, rec in rel_df.iterrows():\n",
    "            if id == rec['qid']:\n",
    "                doc_list.append(rec['docid'])\n",
    "        return doc_list\n",
    "\n",
    "        \n",
    "    def searchNoWhword(self,count):\n",
    "        p = 0\n",
    "        pi = 0\n",
    "        r = 0\n",
    "        ri = 0\n",
    "        f1 = 0\n",
    "        truth =[]\n",
    "        predect = []\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        for i in range(1,50):\n",
    "            q = QueryProcessor(nlp).generate_query(qry_df[i]['doc'])\n",
    "            query = {\n",
    "                        \"match\": {\n",
    "                            \"doc\": q\n",
    "                        }\n",
    "                    }\n",
    "            ids =[]\n",
    "            docs =[]\n",
    "            resp = client.search(index=\"cisi\", query=query, size=count)\n",
    "            for hit in resp['hits']['hits']:\n",
    "                ids.append(hit['_source']['id'])\n",
    "                docs.append(hit['_source']['doc'])\n",
    "            predect.append(ids)\n",
    "            truth.append()\n",
    "            pi = precision(self.rel[str(i+1)], ids)\n",
    "            p = p + pi\n",
    "            ri = recall(self.rel[str(i+1)], ids)\n",
    "            r = r + ri\n",
    "            f1 = f1 + (2 * ((pi * ri)/(pi + ri)))\n",
    "        return p / len(predect), r/len(predect), f1/len(predect)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    def searchNoSW(self,count):\n",
    "        p = 0\n",
    "        pi = 0\n",
    "        r = 0\n",
    "        ri = 0\n",
    "        f1 = 0\n",
    "        truth =[]\n",
    "        predect = []\n",
    "        for i in range(1,35):\n",
    "            q = remove_stopwords(self.qry[i]['doc'] )\n",
    "            query = {\n",
    "                        \"match\": {\n",
    "                            \"doc\": q\n",
    "                        }\n",
    "                    }\n",
    "            ids =[]\n",
    "            docs =[]\n",
    "            resp = client.search(index=\"cisi\", query=query, size=count)\n",
    "            for hit in resp['hits']['hits']:\n",
    "                ids.append(hit['_source']['id'])\n",
    "                docs.append(hit['_source']['doc'])\n",
    "            predect.append(ids)\n",
    "            truth.append(self.rel[str(i+1)])\n",
    "            pi = precision(self.rel[str(i+1)], ids)\n",
    "            p = p + pi\n",
    "            ri = recall(self.rel[str(i+1)], ids)\n",
    "            r = r + ri\n",
    "            f1 = f1 + (2 * ((pi * ri)/(pi + ri)))\n",
    "        return p / len(predect), r/len(predect), f1/len(predect)\n",
    "    \n",
    "\n",
    "    def searchPR(self,count):\n",
    "        p = 0\n",
    "        pi = 0\n",
    "        r = 0\n",
    "        ri = 0\n",
    "        f1 = 0\n",
    "        truth =[]\n",
    "        predect = []\n",
    "        for i, rec in qry_df.iterrows():\n",
    "            if i> 100:\n",
    "                break\n",
    "            query = {\n",
    "                        \"match\": {\n",
    "                            \"doc\": rec['query'] \n",
    "                        }\n",
    "                    }\n",
    "            ids =[]\n",
    "            docs =[]\n",
    "            resp = client.search(index=\"trec\", query=query, size=count)\n",
    "            for hit in resp['hits']['hits']:\n",
    "                ids.append(hit['_source']['id'])\n",
    "                docs.append(hit['_source']['doc'])\n",
    "            predect.append(ids)\n",
    "            \n",
    "            truth.append(self.getTruth(rec['qid']))\n",
    "            pi = precision(self.rel[str(i+1)], ids)\n",
    "            p = p + pi\n",
    "            ri = recall(self.rel[str(i+1)], ids)\n",
    "            r = r + ri\n",
    "            #print(pi,ri)\n",
    "           # f1 = f1 + (2 * ((pi * ri)/(pi + ri)))\n",
    "        return p / len(predect), r/len(predect) , f1/len(predect)\n",
    "\n",
    "nop = noprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nop.searchPR(count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in resp['hits']['hits']:\n",
    "    print(hit['_source'])\n",
    "        # ids.append(hit['_source']['id'])\n",
    "        # docs.append(hit['_source']['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44ee107329cf4a2b10dbf9dc2a835ad7dfaf7406a03f5d729fde60d5b9868961"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
