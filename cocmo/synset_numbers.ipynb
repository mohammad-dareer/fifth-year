{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.matcher import Matcher\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "import numerizer\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "numnlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "nlp.add_pipe(\"merge_noun_chunks\")\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers\n",
    "client = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "     basic_auth=(\"elastic\", \"elastic\")\n",
    "\n",
    ")\n",
    "resp = client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class question_matcher:\n",
    "    def __init__(self):\n",
    "        self.patterns= []\n",
    "        self.q_json = self.get_questions_json()\n",
    "        self.matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    def get_questions_json(self):\n",
    "        with open('questions.json', 'r') as f:\n",
    "            pat = json.load(f)\n",
    "        return pat\n",
    "    \n",
    "    def define_keyword(self,question:str):\n",
    "        keyword = ''\n",
    "        for q in self.q_json:\n",
    "            if q['keyword'] in question.lower():\n",
    "                keyword = q['keyword']\n",
    "                index = q['qid']\n",
    "        return keyword, index\n",
    "\n",
    "    def re_get_focus(self,question:str,ind,pattern):\n",
    "        question_token = [token.text for token in nlp(question)]\n",
    "        focus = ''\n",
    "        focus_pos = pattern['focus']\n",
    "        start = 0\n",
    "        i = 0\n",
    "        for token in focus_pos[ind].split('\\s*'):\n",
    "                if(token == 'sf'):\n",
    "                    start = 1\n",
    "                    i = i - 1\n",
    "                    continue\n",
    "\n",
    "                if(token == 'ef'):\n",
    "                    start = 0\n",
    "                    break\n",
    "\n",
    "                if(token == \".*\" and start == 1):\n",
    "                    j = i\n",
    "                    while(j < len(question_token)):\n",
    "                        focus = focus + ' ' + question_token[j]\n",
    "                        j = j + 1\n",
    "                    focus = focus.strip()\n",
    "                    print(focus)\n",
    "                    return focus\n",
    "\n",
    "                if(start == 1):\n",
    "                    focus = focus + ' ' + question_token[i]\n",
    "                i = i + 1\n",
    "        focus = focus.strip()\n",
    "        print(focus)\n",
    "        return focus\n",
    "\n",
    "    def re_match_pattern(self,question):\n",
    "        found = 0\n",
    "        doc = nlp(question)\n",
    "        ltoken = [token.pos_ for token in nlp(question)]\n",
    "        q_pattern = ''\n",
    "        for token in doc:\n",
    "            q_pattern = q_pattern + token.pos_ + ' ' \n",
    "        keyword, index = self.define_keyword(question)\n",
    "        for pattern in self.q_json[index]['patterns']:\n",
    "            matched_pos=0\n",
    "            for pos in pattern['pos']:\n",
    "                regexpos  = f'({pos})'\n",
    "                matches = re.fullmatch(regexpos, q_pattern)\n",
    "                if matches != None:\n",
    "                    #print('Matched!')\n",
    "                    # print(matches.string)\n",
    "                    # print(pos)\n",
    "                    # print(pattern['pattern'])\n",
    "                    focus = self.re_get_focus(question,matched_pos,pattern)\n",
    "                    found = 1\n",
    "                    return focus, pattern['answerType']\n",
    "                matched_pos = matched_pos + 1\n",
    "            if found == 1:\n",
    "                break\n",
    " \n",
    "    def pattern_to_pos(self, patterns:list):\n",
    "        pos = []\n",
    "        pattern = []\n",
    "        for p in patterns:\n",
    "            \n",
    "            itr = []\n",
    "            pattern.append(p)\n",
    "            for token in p.split():\n",
    "                if token != '*':\n",
    "                    itr.append({'POS':token})\n",
    "                else:\n",
    "                    itr.append({})\n",
    "            pos.append(itr)\n",
    "        return pos\n",
    "qm = question_matcher()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched!\n",
      "more than ten people\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('more than ten people', 'entity')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qm.re_match_pattern(\"images that contain more than ten people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class retrive_image:\n",
    "    def __init__(self):\n",
    "        self.image_ids =[]\n",
    "        self.image_caption =[]\n",
    "\n",
    "    def search(self,query):\n",
    "        self.image_ids =[]\n",
    "        self.image_caption =[]\n",
    "        query = {\n",
    "            \"match\": {\n",
    "            \"caption\": query\n",
    "            }\n",
    "        }\n",
    "        resp = client.search(index=\"cocomo\", query=query,size=100)\n",
    "        #print(\"Got %d Hits:\" % resp['hits']['total']['value'])\n",
    "        for hit in resp['hits']['hits']:\n",
    "            #  print(\\\"%(caption)s : %(image_id)s : %(id)s\\\" % hit[\\\"_source\\\"])\\n\",\n",
    "            self.image_ids.append(hit['_source']['image_id'])\n",
    "            self.image_caption.append(hit['_source']['caption'])\n",
    "       # self.display();\n",
    "        \n",
    "    def display(self):\n",
    "        i = 0\n",
    "        plt.figure(figsize=(25,50))\n",
    "        columns = 2\n",
    "        for i, id in enumerate(self.image_ids):\n",
    "            plt.subplot(10, 3, i + 1)\n",
    "            path = '..\\\\..\\\\Cocomo2014\\\\\\\\val2014\\\\\\\\val2014\\\\COCO_val2014_'+ '0'*(12 - len(str(id))) + str(id) +'.jpg'\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.title(self.image_caption[i])\n",
    "            plt.imshow(img)\n",
    "ir = retrive_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class system1:\n",
    "    def __init__(self):\n",
    "        qm = question_matcher()\n",
    "        ir = retrive_image()\n",
    "        self.image_captions = []\n",
    "        self.image_ids = []\n",
    "        self.data = pd.DataFrame()\n",
    "    \n",
    "    def search(self,question):\n",
    "        focus, eat =  qm.re_match_pattern(question)\n",
    "        print(focus)\n",
    "        ir.search('people')\n",
    "       # print(eat)\n",
    "        self.image_captions = ir.image_caption\n",
    "        self.image_ids = ir.image_ids\n",
    "        self.data = pd.DataFrame({\"caption\":self.image_captions, \"id\":self.image_ids, \"EAT\":[0]*len(self.image_ids),\"similarity\":[0]*len(self.image_ids),\"num\":[0]*len(self.image_ids)})\n",
    "        #print(self.data.head())\n",
    "        #self.get_image_with_correct_synset(eat, focus)\n",
    "        self.get_image_with_number(focus)\n",
    "        self.data = self.data.sort_values(by=['EAT','num'],ascending=False)\n",
    "        print(self.data.head(50))\n",
    "        #self.display(self.data.head(50)['caption'],self.data.head(50)['id'])\n",
    "        #print(self.data['caption'].at[5])\n",
    "    \n",
    "    # def creating_query(self, qid, focus):\n",
    "    #     if qid < 4:\n",
    "    #         return focus\n",
    "    #     if qid == 4:\n",
    "            \n",
    "\n",
    "    def get_image_with_correct_synset(self, eat:str, focus:str):\n",
    "        for index, row in self.data.iterrows():\n",
    "            self.data.at[index, 'similarity'] = nlp(focus).similarity(nlp(row['caption']))\n",
    "            for token in row['caption'].split():\n",
    "                # if(token.is_stop):\n",
    "                #     continue\n",
    "                #print(token)\n",
    "                cond = self.check_hypernym(token, eat)\n",
    "\n",
    "                if (cond == 'True'):\n",
    "                    self.data.at[index, 'EAT'] = 1\n",
    "                    # break\n",
    "            \n",
    "            # for ent in nlp(row['caption']).ents:\n",
    "            #     if(eat == 'person' and ent.label_ == 'PERSON'):\n",
    "            #         self.data.at[index, 'EAT'] = 1\n",
    "                    \n",
    "       # return aftercap, afterids\n",
    "\n",
    "\n",
    "\n",
    "    def get_image_with_number(self, focus:str):\n",
    "        focus_head, focus_num = self.get_num_with_head(focus)\n",
    "        for index, row in self.data.iterrows():\n",
    "            for token in row['caption'].split():\n",
    "                if(nlp(token)[0].pos_ == 'NUM'):\n",
    "                    self.data.at[index, 'EAT'] = 1\n",
    "               \n",
    "                    fuck = str(row['caption'])\n",
    "                    #print(fuck)\n",
    "                    word_head, word_num =  self.get_num_with_head(fuck)\n",
    "                    if(word_head == focus_head and word_num>=focus_num):\n",
    "                        self.data.at[index, 'num'] = 1\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "    def get_num_with_head(self,s:str):\n",
    "        doc = numnlp(s)\n",
    "        for token in doc:\n",
    "            if(token.dep_ == 'nummod'):\n",
    "                num = list(numnlp(token.text)._.numerize().values())[0]\n",
    "                return token.head.text, float(num)\n",
    "\n",
    "        \n",
    "    def check_hypernym(self ,word:str ,sett:str):\n",
    "        word_lamma = nlp(word)[0].lemma_\n",
    "        sett_lamma = nlp(sett)[0].lemma_\n",
    "\n",
    "        if(wn.synsets(word_lamma) == []):\n",
    "            return 'False'\n",
    "        word_ss = wn.synsets(word_lamma)[0]\n",
    "\n",
    "        if(wn.synsets(sett_lamma) == []):\n",
    "            return 'False'\n",
    "        sett_ss = set(ss.name() for ss in wn.synsets(sett_lamma))\n",
    "        hypernyms_ss = {synset.name() for synset in wn.synset(word_ss.name()).hypernym_paths()[0]}\n",
    "        z = sett_ss.intersection(hypernyms_ss)\n",
    "        if(len(list(z)) != 0):\n",
    "           # print('yezzzz')\n",
    "            return 'True'\n",
    "        return 'False'\n",
    "\n",
    "\n",
    "\n",
    "    def display(self,caps,ids):\n",
    "        i = 0\n",
    "        plt.figure(figsize=(25,50))\n",
    "        for i, id in enumerate(ids):\n",
    "            plt.subplot(18, 2, i + 1)\n",
    "            path = '..\\\\..\\\\Cocomo2014\\\\\\\\val2014\\\\\\\\val2014\\\\COCO_val2014_'+ '0'*(12 - len(str(self.data.head(50)['id'][i]))) + str(self.data.head(50)['id'][i]) +'.jpg'\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.title(self.data.head(50)['caption'][i])\n",
    "            plt.imshow(img)\n",
    "s1 = system1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than two people\n",
      "more than two people\n",
      "                                              caption      id  EAT  \\\n",
      "0     Four people watching 3 other people race horses  439481    1   \n",
      "2   some people are watching two people playing te...  422522    1   \n",
      "7   Two people with umbrellas near other people wi...   20774    1   \n",
      "14  People sitting in the grass while two people a...   88682    1   \n",
      "15  Two people riding a motorcycle near a group of...  331785    1   \n",
      "18  Two people on horses surrounded by a crowd of ...   94055    1   \n",
      "20  many people sitting on a field with two people...  578441    1   \n",
      "21  Two people in skis racing up slope with people...  538115    1   \n",
      "23  Two people playing a video game with three peo...  324322    1   \n",
      "25  Three people people in a kitchen preparing foo...  369259    1   \n",
      "36  Two people playing tennis on a tennis court wh...   36226    1   \n",
      "39  Two people are playing wii together and laughi...  140332    1   \n",
      "42  Two people sit on a bench with pigeons and oth...  548780    1   \n",
      "44  Two people playing Frisbee are being watched b...  529592    1   \n",
      "45  Lots of people in the water and 2 people in a ...  296182    1   \n",
      "46  two people eating at a table and many people a...  421360    1   \n",
      "48  Two people  seated at a table with other peopl...   65655    1   \n",
      "49  two people smiling and using cellular phones i...  419158    1   \n",
      "50  Two people taking a picture together next to a...  340278    1   \n",
      "51  A group of people hanging out with two people ...  505818    1   \n",
      "57  Two people sking down a ski slope while people...  452816    1   \n",
      "62  Two people sitting and two people walking thro...  378658    1   \n",
      "64  Two people sitting on a bench looking at peopl...  190018    1   \n",
      "65  two people posing for a photo with young peopl...  270852    1   \n",
      "66  two people and a small child some grass and ot...  517823    1   \n",
      "72  Two people walking under an umbrella and anoth...  251910    1   \n",
      "73  People watch while two people are on a small r...   71301    1   \n",
      "75  two people in scuba diving wear  walking on sa...  247264    1   \n",
      "77            Two people riding horses along  a trail  364113    1   \n",
      "78            Two cosplaying people pose for a photo    62483    1   \n",
      "83    two people riding motorcycles near one another    15596    1   \n",
      "85     Two people on bikes crossing an intersection.    84540    1   \n",
      "92     two people riding motorcycles near each other   204906    1   \n",
      "93              Three people watch a train drive by.   101913    1   \n",
      "96            two people in a kitchen preparing food   512667    1   \n",
      "97           two people in a kitchen near appliances   106228    1   \n",
      "58  some people and signs a bicycle two horses pul...  515303    1   \n",
      "1   people playing a baseball and many people watc...  439994    0   \n",
      "3        People are watching other people fly a kite.  378048    0   \n",
      "4    Group of people flying kites shaped like people.  574487    0   \n",
      "5   people exiting a train and people entering a t...  471642    0   \n",
      "6   People walking along the streets while people ...  573930    0   \n",
      "8   A group of people near some people riding horses.  439481    0   \n",
      "9   A group of people watch other people race horses.  439481    0   \n",
      "10  some people sitting  on benches and some peopl...  249277    0   \n",
      "11  a bunch of people playing baseball as people w...  302067    0   \n",
      "12  There are people watching other people play ta...   96306    0   \n",
      "13  People playing and people watching a game of b...   50975    0   \n",
      "16  A plane with people watching it and people nea...  448288    0   \n",
      "17  People trying to rescue other people from a tr...   47131    0   \n",
      "\n",
      "    similarity  num  \n",
      "0            0    1  \n",
      "2            0    1  \n",
      "7            0    1  \n",
      "14           0    1  \n",
      "15           0    1  \n",
      "18           0    1  \n",
      "20           0    1  \n",
      "21           0    1  \n",
      "23           0    1  \n",
      "25           0    1  \n",
      "36           0    1  \n",
      "39           0    1  \n",
      "42           0    1  \n",
      "44           0    1  \n",
      "45           0    1  \n",
      "46           0    1  \n",
      "48           0    1  \n",
      "49           0    1  \n",
      "50           0    1  \n",
      "51           0    1  \n",
      "57           0    1  \n",
      "62           0    1  \n",
      "64           0    1  \n",
      "65           0    1  \n",
      "66           0    1  \n",
      "72           0    1  \n",
      "73           0    1  \n",
      "75           0    1  \n",
      "77           0    1  \n",
      "78           0    1  \n",
      "83           0    1  \n",
      "85           0    1  \n",
      "92           0    1  \n",
      "93           0    1  \n",
      "96           0    1  \n",
      "97           0    1  \n",
      "58           0    0  \n",
      "1            0    0  \n",
      "3            0    0  \n",
      "4            0    0  \n",
      "5            0    0  \n",
      "6            0    0  \n",
      "8            0    0  \n",
      "9            0    0  \n",
      "10           0    0  \n",
      "11           0    0  \n",
      "12           0    0  \n",
      "13           0    0  \n",
      "16           0    0  \n",
      "17           0    0  \n"
     ]
    }
   ],
   "source": [
    "s1.search('images that contain more than two people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', 'll']\n"
     ]
    }
   ],
   "source": [
    "sy = {'s': 'l', 'm0':'ll'}\n",
    "print(list(sy.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_eat(entity):\n",
    "    person = wn.synsets('person')\n",
    "    person_ss = set(ss.name() for ss in wn.synsets('person'))\n",
    "    location_ss = set(ss.name() for ss in wn.synsets('location'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-ce36c353bd3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mget_num_with_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"more than three other people and ten dogs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-ce36c353bd3d>\u001b[0m in \u001b[0;36mget_num_with_head\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m#if(token.dep_ == 'nummod'):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mget_num_with_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"more than three other people and ten dogs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def get_num_with_head(s:str):\n",
    "    doc = numnlp(s)\n",
    "    for token in doc:\n",
    "        if(token.dep_ == 'nummod'):\n",
    "            num = list(numnlp(token.text)._.numerize().values())[0]\n",
    "            return token.head.text, float(num)\n",
    "get_num_with_head(\"more than three other people and ten dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more amod three NUM []\n",
      "than quantmod three NUM []\n",
      "three nummod people NOUN [more, than]\n",
      "other amod people NOUN []\n",
      "people ROOT people NOUN [three, other]\n"
     ]
    }
   ],
   "source": [
    "doc = numnlp(\"more than three other people\")\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])\n",
    "num = doc._.numerize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('three people and dogs')\n",
    "doc._.numerize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_antonym_extractor(phrase):\n",
    "     from nltk.corpus import wordnet\n",
    "     synonyms = []\n",
    "     antonyms = []\n",
    "\n",
    "     for syn in wordnet.synsets(phrase):\n",
    "          for l in syn.lemmas():\n",
    "               synonyms.append(l.name())\n",
    "               if l.antonyms():\n",
    "                    antonyms.append(l.antonyms()[0].name())\n",
    "     print(set(synonyms))\n",
    "     print(set(antonyms))\n",
    "synonym_antonym_extractor(phrase=\"house\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44ee107329cf4a2b10dbf9dc2a835ad7dfaf7406a03f5d729fde60d5b9868961"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
